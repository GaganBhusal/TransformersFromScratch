{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(d_model, vocab_size)\n",
    "        # shape = [num of words * dimension of embedding layer]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(d_model)\n",
    "        # dimension same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, seq_length, dropout = 0):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(self.seq_length, self.d_model)  # To get the matrix of dimension as of embedding layer\n",
    "        positions = torch.arange(0, self.seq_length, dtype = torch.float32).unsqueeze(1)  # matrix of [seq_length x 1]\n",
    "        div_term = (positions /(torch.pow(10000, 2 * torch.arange(0, d_model, 2).float() /self.d_model))) #to calculate say (angle)  pos/(10000^(2i/dmodel))\n",
    "        pe[:, 0::2] = torch.sin(div_term)   #Apply sine formula in even positions\n",
    "        pe[:, 1::2] = torch.cos(div_term)   # Appply cosine formula in odd positions\n",
    "        \n",
    "        self.pe = pe.unsqueeze(0)  # for batches dimension [1 x seq_length x d_model]\n",
    "\n",
    "        # self.register_buffer('pe', self.pe) # By adding this in register buffer this stores pe too while saving the model without considering it as a learning parameter\n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe.required_grad(False)  #To make it not to learn\n",
    "        return self.dropout(x)\n",
    "    # def forward(self, ..):\n",
    "        # pe = torch.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, epsilon=1e-5):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = nn.Parameter(torch.ones(1))  # Scale\n",
    "        self.beta = nn.Parameter(torch.zeros(1))  # Shift\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=1, keepdim=True)\n",
    "        var = x.var(dim=1, keepdim=True) \n",
    "        return self.gamma * (x - mean) / torch.sqrt(var + self.epsilon) + self.beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dff, dropout = 0.5):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.forward1 = nn.Linear(d_model, dff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.forward2 = nn.Linear(dff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.forward2(self.dropout(torch.relu(self.forward1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE I USED ALL EMBEDDING FOR EACH HEAD AND CONCATENATE THEM AND USE LINEAR TRANSFORMATION TO GET THE OUTPUT SAME DIMENSION AS INPUT\n",
    "# class MultiHeadAttention(nn.Module):\n",
    "\n",
    "#     def __init__(self, d_model, heads, dropout = 0.5):\n",
    "#         super(MultiHeadAttention, self).__init__()\n",
    "#         self.d_model = d_model\n",
    "#         self.heads = heads\n",
    "#         self.dropout = dropout\n",
    "\n",
    "#         self.w_q = nn.ModuleList(nn.Linear(d_model, d_model) for _ in range(heads))\n",
    "#         self.w_k = nn.ModuleList(nn.Linear(d_model, d_model) for _ in range(heads))\n",
    "#         self.w_v = nn.ModuleList(nn.Linear(d_model, d_model) for _ in range(heads))\n",
    "\n",
    "#         self.w_o = nn.Linear(d_model * heads, d_model)\n",
    "\n",
    "#         self.softmax = nn.Softmax(dim = -1)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "#     def forward(self, embeded_layer):\n",
    "\n",
    "#         attention_outputs = []\n",
    "\n",
    "#         for head in range(self.heads):\n",
    "        \n",
    "#             query = self.w_q[head](embeded_layer)\n",
    "#             key = self.w_k[head](embeded_layer)\n",
    "#             value = self.w_v[head](embeded_layer)\n",
    "\n",
    "#             similarity = torch.matmul(query, torch.transpose(key, -2, -1))  / math.sqrt(self.d_model)\n",
    "\n",
    "#             sim = self.softmax(similarity)\n",
    "#             sim = self.dropout(sim)\n",
    "\n",
    "#             final = torch.matmul(sim, value)\n",
    "\n",
    "#             attention_outputs.append(final)\n",
    "            \n",
    "#         concat_matrix = torch.cat(attention_outputs, -1)\n",
    "#         print(concat_matrix.shape)\n",
    "#         print(self.w_o.weight.shape)\n",
    "#         return self.w_o(concat_matrix)\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, heads, dropout = 0.5):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = heads\n",
    "        self.d_heads = d_model//heads\n",
    "\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    \n",
    "    # def splitweights(self, x):\n",
    "    #     batch_size, seq_len, d_model = x.shape\n",
    "    #     x = x.view(batch_size, seq_len, self.heads, -1)\n",
    "    #     return x.permute(0, 2, 1, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, x_q, x_k, x_v, mask = None):\n",
    "\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        print(x.shape)\n",
    "        print(self.w_q.weight.shape)\n",
    "\n",
    "        query = self.w_q(x_q).view(batch_size, seq_len, self.heads, -1).permute(0, 2, 1, 3)\n",
    "        key = self.w_k(x_k).view(batch_size, seq_len, self.heads, -1).permute(0, 2, 1, 3)\n",
    "        value = self.w_v(x_v).view(batch_size, seq_len, self.heads, -1).permute(0, 2, 1, 3)\n",
    "\n",
    "        # query = self.splitweights(self.w_q(x))\n",
    "        # key = self.splitweights(self.w_k(x))\n",
    "        # value = self.splitweights(self.w_v(x))\n",
    "        print(query.shape)\n",
    "\n",
    "        similarity = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_heads)\n",
    "\n",
    "        # print(similarity.shape)\n",
    "\n",
    "        if mask is not None:\n",
    "            # print(mask)\n",
    "            mask = mask.unsqueeze(0).unsqueeze(0)\n",
    "            print(mask)\n",
    "            # print(similarity)\n",
    "            similarity = similarity.masked_fill(mask == 0, float('-inf'))\n",
    "        print(similarity)\n",
    "\n",
    "        sim = self.softmax(similarity)\n",
    "        print(sim)\n",
    "        sim = self.dropout(sim)\n",
    "\n",
    "        # print(sim)\n",
    "\n",
    "        final = torch.matmul(sim, value)\n",
    "\n",
    "        final = final.permute(0, 2, 1, 3).contiguous()\n",
    "        final = final.view(batch_size, seq_len, self.d_model)\n",
    "        \n",
    "\n",
    "        # print(final.shape)\n",
    "        return self.w_o(final)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 15])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([2, 3, 4, 5])\n",
      "tensor([[[[1., 0., 0., 0.],\n",
      "          [1., 1., 0., 0.],\n",
      "          [1., 1., 1., 0.],\n",
      "          [1., 1., 1., 1.]]]])\n",
      "tensor([[[[-0.0646,    -inf,    -inf,    -inf],\n",
      "          [-0.2716, -0.2415,    -inf,    -inf],\n",
      "          [-0.0717, -0.0256, -0.0467,    -inf],\n",
      "          [-0.1440, -0.0869, -0.0978, -0.0046]],\n",
      "\n",
      "         [[ 0.0781,    -inf,    -inf,    -inf],\n",
      "          [ 0.0805,  0.1700,    -inf,    -inf],\n",
      "          [ 0.0661,  0.1286,  0.1260,    -inf],\n",
      "          [ 0.1080,  0.2245,  0.1626,  0.1165]],\n",
      "\n",
      "         [[ 0.0143,    -inf,    -inf,    -inf],\n",
      "          [ 0.0402,  0.0663,    -inf,    -inf],\n",
      "          [-0.0066,  0.0325, -0.0255,    -inf],\n",
      "          [ 0.0693,  0.0965,  0.0507,  0.1064]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0176,    -inf,    -inf,    -inf],\n",
      "          [-0.1221, -0.1537,    -inf,    -inf],\n",
      "          [ 0.1109,  0.0653, -0.0153,    -inf],\n",
      "          [-0.0069, -0.0655, -0.0772, -0.1229]],\n",
      "\n",
      "         [[ 0.1134,    -inf,    -inf,    -inf],\n",
      "          [ 0.1243,  0.0466,    -inf,    -inf],\n",
      "          [ 0.1400,  0.0435,  0.1003,    -inf],\n",
      "          [ 0.1565,  0.0626,  0.1449,  0.2190]],\n",
      "\n",
      "         [[ 0.0493,    -inf,    -inf,    -inf],\n",
      "          [ 0.0636,  0.0940,    -inf,    -inf],\n",
      "          [ 0.0330,  0.0098,  0.1214,    -inf],\n",
      "          [ 0.0648,  0.0672,  0.1200,  0.0287]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4925, 0.5075, 0.0000, 0.0000],\n",
      "          [0.3255, 0.3408, 0.3337, 0.0000],\n",
      "          [0.2350, 0.2488, 0.2461, 0.2701]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4776, 0.5224, 0.0000, 0.0000],\n",
      "          [0.3199, 0.3405, 0.3396, 0.0000],\n",
      "          [0.2388, 0.2683, 0.2522, 0.2408]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4935, 0.5065, 0.0000, 0.0000],\n",
      "          [0.3310, 0.3442, 0.3248, 0.0000],\n",
      "          [0.2471, 0.2539, 0.2425, 0.2565]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5079, 0.4921, 0.0000, 0.0000],\n",
      "          [0.3525, 0.3368, 0.3107, 0.0000],\n",
      "          [0.2655, 0.2504, 0.2475, 0.2365]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5194, 0.4806, 0.0000, 0.0000],\n",
      "          [0.3486, 0.3165, 0.3350, 0.0000],\n",
      "          [0.2523, 0.2297, 0.2494, 0.2686]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4924, 0.5076, 0.0000, 0.0000],\n",
      "          [0.3258, 0.3183, 0.3559, 0.0000],\n",
      "          [0.2485, 0.2491, 0.2626, 0.2397]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.9217e-01,  4.1111e-01, -3.6354e-01,  1.0093e-01, -2.8318e-01,\n",
       "           1.2245e-01, -3.4632e-01, -4.9421e-01, -7.9851e-02, -3.9060e-01,\n",
       "          -1.1471e-01, -3.4894e-01,  2.3361e-01,  3.6919e-01, -6.3525e-02],\n",
       "         [ 3.9308e-01,  4.2863e-01, -1.3260e-01, -3.8364e-01, -2.7997e-01,\n",
       "           3.7850e-01,  2.3257e-01, -4.4453e-01,  1.8895e-01, -1.7295e-02,\n",
       "          -2.3405e-01, -3.2712e-01, -3.0418e-02,  1.0180e-01, -8.9230e-02],\n",
       "         [ 2.0156e-01,  2.3251e-01, -9.0549e-02, -1.7442e-01, -2.1672e-01,\n",
       "           3.5292e-01, -2.3715e-02, -3.0320e-01,  1.3038e-01, -3.9166e-02,\n",
       "          -1.0064e-01, -2.9928e-01,  4.3222e-04,  1.4415e-01, -7.0526e-02],\n",
       "         [ 3.5503e-01,  8.9544e-02,  1.0058e-01, -1.6942e-01, -3.2579e-01,\n",
       "           2.4582e-01, -1.3218e-01, -2.6041e-01,  6.7314e-02,  2.0481e-02,\n",
       "          -1.6789e-01, -3.1246e-01,  1.1793e-01,  2.5790e-01, -9.9997e-02]],\n",
       "\n",
       "        [[ 1.8646e-01,  2.4953e-01, -1.4703e-01,  9.3062e-02,  1.2746e-01,\n",
       "           4.2917e-01,  5.5582e-03, -1.4693e-01, -7.1955e-02, -1.4349e-01,\n",
       "          -9.9293e-02, -5.8369e-02, -1.3674e-01,  1.9616e-01,  9.2322e-02],\n",
       "         [ 2.9307e-01,  5.6768e-03,  1.2245e-01,  2.3178e-03, -3.7133e-01,\n",
       "           1.8802e-01, -2.2051e-01, -2.0004e-01,  5.3121e-02,  4.5087e-03,\n",
       "          -1.5607e-02, -2.3882e-01,  1.7933e-01,  2.1447e-01, -1.0098e-01],\n",
       "         [ 2.1686e-01,  8.1603e-02,  9.2127e-02, -3.6584e-03, -1.0979e-01,\n",
       "           2.4633e-01, -7.0868e-02, -1.5723e-01,  4.9405e-02, -4.1274e-02,\n",
       "          -1.3691e-01, -1.4539e-01,  1.0131e-02,  2.1285e-01, -4.3217e-02],\n",
       "         [ 3.1858e-01,  2.2470e-01,  9.8778e-03, -1.3568e-01, -3.4787e-01,\n",
       "           2.9691e-01, -1.2542e-01, -2.9430e-01,  3.1695e-02, -6.2115e-02,\n",
       "          -1.2699e-01, -4.8661e-01,  9.4352e-02,  1.2249e-01, -1.3955e-01]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.tril(torch.ones(4, 4))\n",
    "x = torch.rand(2, 4 ,15)\n",
    "a = MultiHeadAttention(15, 3)\n",
    "a(x,x,x, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model ,dropout):\n",
    "\n",
    "        super(ResidualConnection, self).__init__()\n",
    "        self.ln = LayerNormalization()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        return self.ln(x1 + self.dropout(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self,  dff, d_model, heads, dropout):\n",
    "\n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        self.multi_attention = MultiHeadAttention(d_model, heads, dropout)\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(d_model, dropout) for _ in range(2)])\n",
    "\n",
    "        self.feed_forward = FeedForward(d_model, dff)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x1, key, value = self.multi_attention(x, x, x)\n",
    "        x2 = self.residual_connections[0](x, x1)\n",
    "        x3 = self.feed_forward(x2)\n",
    "        x4 = self.residual_connections[1](x2, x3)\n",
    "        return x4\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, dff, seq_length, d_model, heads,dropout, n = 6):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding_layer = InputEmbedding(d_model, vocab_size)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, seq_length, dropout)\n",
    "        \n",
    "        self.encoder_blocks = nn.ModuleList([EncoderBlock(dff, d_model, heads,dropout) for _ in range(n)])\n",
    "        print(type(self.encoder_blocks))\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.positional_encoding(self.embedding_layer(x))\n",
    "\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dff, d_model, heads, dropout):\n",
    "\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        # self.masked_attention = masked_attention\n",
    "        # self.residual_connections = residual_connections\n",
    "        # self.cross_attention = cross_attention\n",
    "        # self.feed_forward = feed_forward\n",
    "        self.masked_attention = MultiHeadAttention(d_model, heads)\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(d_model, dropout) for _ in range(3)])\n",
    "        self.cross_attention = MultiHeadAttention(d_model, heads)\n",
    "        self.feed_forward = FeedForward(d_model, dff)\n",
    "\n",
    "\n",
    "    def forward(self, x, x_enc, mask):\n",
    "\n",
    "        x1= self.masked_attention(x, x, x, mask)\n",
    "        x2 = self.residual_connections[0](x, x1)\n",
    "\n",
    "        x3= self.cross_attention(x2, x_enc, x_enc)\n",
    "        x4 = self.residual_connections[1](x2, x3)\n",
    "\n",
    "        x5 = self.feed_forward(x4)\n",
    "        x6 = self.residual_connections[2](x4, x5)\n",
    "\n",
    "        return x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, dff, seq_length, d_model, heads,dropout, n = 6):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.embedding_layer = InputEmbedding(d_model, vocab_size)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, seq_length, dropout)\n",
    "\n",
    "        self.decoder_blocks = nn.ModuleList([DecoderBlock(dff, d_model, heads,dropout) for _ in range(n)])\n",
    "\n",
    "        self.mask = m = torch.tril(torch.ones(seq_length, seq_length))\n",
    "\n",
    "        self.linear = nn.Linear(d_model, vocab_size)\n",
    "        self.softmax = nn.Softmax(dim = -1)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x, x_enc):\n",
    "\n",
    "        x = self.positional_encoding(self.embedding_layer(x))\n",
    "        for block in self.decoder_blocks:\n",
    "            x = block(x, x_enc, self.mask)\n",
    "        return self.softmax(self.linear(x))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size_source, vocab_size_target, seq_length_source, seq_length_taeget, d_model = 512, heads = 8, dropout = 0.1, dff = 2048):\n",
    "\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(vocab_size_source, dff, seq_length_source, d_model, heads, dropout)\n",
    "        self.decoder = Decoder(vocab_size_target, dff, seq_length_target, d_model, heads, dropout)\n",
    "\n",
    "        for parameter in self.parameters():\n",
    "            nn.init.xavier_uniform_(parameter)\n",
    "\n",
    "    def forward(self, x_in, x_op):\n",
    "\n",
    "        x_enc= self.encoder(x_in)\n",
    "        output = self.decoder(x_op, x_enc, x_enc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = torch.rand((4, 3, 3))\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = nn.Softmax(dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(4, 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.view(4, 5, 2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
