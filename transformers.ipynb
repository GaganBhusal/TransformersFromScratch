{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(d_model, vocab_size)\n",
    "        # shape = [num of words * dimension of embedding layer]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(d_model)\n",
    "        # dimension same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, seq_length, dropout = 0):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(self.seq_length, self.d_model)  # To get the matrix of dimension as of embedding layer\n",
    "        positions = torch.arange(0, self.seq_length, dtype = torch.float32).unsqueeze(1)  # matrix of [seq_length x 1]\n",
    "        div_term = (positions /(torch.pow(10000, 2 * torch.arange(0, d_model, 2).float() /self.d_model))) #to calculate say (angle)  pos/(10000^(2i/dmodel))\n",
    "        pe[:, 0::2] = torch.sin(div_term)   #Apply sine formula in even positions\n",
    "        pe[:, 1::2] = torch.cos(div_term)   # Appply cosine formula in odd positions\n",
    "        \n",
    "        self.pe = pe.unsqueeze(0)  # for batches dimension [1 x seq_length x d_model]\n",
    "\n",
    "        # self.register_buffer('pe', self.pe) # By adding this in register buffer this stores pe too while saving the model without considering it as a learning parameter\n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe.required_grad(False)  #To make it not to learn\n",
    "        return self.dropout(x)\n",
    "    # def forward(self, ..):\n",
    "        # pe = torch.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, epsilon=1e-5):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = nn.Parameter(torch.ones(1))  # Scale\n",
    "        self.beta = nn.Parameter(torch.zeros(1))  # Shift\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=1, keepdim=True)\n",
    "        var = x.var(dim=1, keepdim=True) \n",
    "        return self.gamma * (x - mean) / torch.sqrt(var + self.epsilon) + self.beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dff):\n",
    "        super().__init__()\n",
    "        self.forward1 = nn.Linear(d_model, dff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.forward2 = nn.Linear(dff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.forward2(self.dropout(torch.relu(self.forward1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE I USED ALL EMBEDDING FOR EACH HEAD AND CONCATENATE THEM AND USE LINEAR TRANSFORMATION TO GET THE OUTPUT SAME DIMENSION AS INPUT\n",
    "# class MultiHeadAttention(nn.Module):\n",
    "\n",
    "#     def __init__(self, d_model, heads, dropout = 0.5):\n",
    "#         super(MultiHeadAttention, self).__init__()\n",
    "#         self.d_model = d_model\n",
    "#         self.heads = heads\n",
    "#         self.dropout = dropout\n",
    "\n",
    "#         self.w_q = nn.ModuleList(nn.Linear(d_model, d_model) for _ in range(heads))\n",
    "#         self.w_k = nn.ModuleList(nn.Linear(d_model, d_model) for _ in range(heads))\n",
    "#         self.w_v = nn.ModuleList(nn.Linear(d_model, d_model) for _ in range(heads))\n",
    "\n",
    "#         self.w_o = nn.Linear(d_model * heads, d_model)\n",
    "\n",
    "#         self.softmax = nn.Softmax(dim = -1)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "#     def forward(self, embeded_layer):\n",
    "\n",
    "#         attention_outputs = []\n",
    "\n",
    "#         for head in range(self.heads):\n",
    "        \n",
    "#             query = self.w_q[head](embeded_layer)\n",
    "#             key = self.w_k[head](embeded_layer)\n",
    "#             value = self.w_v[head](embeded_layer)\n",
    "\n",
    "#             similarity = torch.matmul(query, torch.transpose(key, -2, -1))  / math.sqrt(self.d_model)\n",
    "\n",
    "#             sim = self.softmax(similarity)\n",
    "#             sim = self.dropout(sim)\n",
    "\n",
    "#             final = torch.matmul(sim, value)\n",
    "\n",
    "#             attention_outputs.append(final)\n",
    "            \n",
    "#         concat_matrix = torch.cat(attention_outputs, -1)\n",
    "#         print(concat_matrix.shape)\n",
    "#         print(self.w_o.weight.shape)\n",
    "#         return self.w_o(concat_matrix)\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, heads, dropout = 0.5):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = heads\n",
    "        self.d_heads = d_model//heads\n",
    "\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    \n",
    "    # def splitweights(self, x):\n",
    "    #     batch_size, seq_len, d_model = x.shape\n",
    "    #     x = x.view(batch_size, seq_len, self.heads, -1)\n",
    "    #     return x.permute(0, 2, 1, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, x_q, x_k, x_v, mask = None):\n",
    "\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        print(x.shape)\n",
    "        print(self.w_q.weight.shape)\n",
    "\n",
    "        query = self.w_q(x_q).view(batch_size, seq_len, self.heads, -1).permute(0, 2, 1, 3)\n",
    "        key = self.w_k(x_k).view(batch_size, seq_len, self.heads, -1).permute(0, 2, 1, 3)\n",
    "        value = self.w_v(x_v).view(batch_size, seq_len, self.heads, -1).permute(0, 2, 1, 3)\n",
    "\n",
    "        # query = self.splitweights(self.w_q(x))\n",
    "        # key = self.splitweights(self.w_k(x))\n",
    "        # value = self.splitweights(self.w_v(x))\n",
    "        print(query.shape)\n",
    "\n",
    "        similarity = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_heads)\n",
    "\n",
    "        # print(similarity.shape)\n",
    "\n",
    "        if mask is not None:\n",
    "            # print(mask)\n",
    "            mask = mask.unsqueeze(0).unsqueeze(0)\n",
    "            print(mask)\n",
    "            # print(similarity)\n",
    "            similarity = similarity.masked_fill(mask == 0, float('-inf'))\n",
    "        print(similarity)\n",
    "\n",
    "        sim = self.softmax(similarity)\n",
    "        print(sim)\n",
    "        sim = self.dropout(sim)\n",
    "\n",
    "        # print(sim)\n",
    "\n",
    "        final = torch.matmul(sim, value)\n",
    "\n",
    "        final = final.permute(0, 2, 1, 3).contiguous()\n",
    "        final = final.view(batch_size, seq_len, self.d_model)\n",
    "        \n",
    "\n",
    "        # print(final.shape)\n",
    "        return self.w_o(final), key, value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 15])\n",
      "torch.Size([15, 15])\n",
      "torch.Size([2, 3, 4, 5])\n",
      "tensor([[[[1., 0., 0., 0.],\n",
      "          [1., 1., 0., 0.],\n",
      "          [1., 1., 1., 0.],\n",
      "          [1., 1., 1., 1.]]]])\n",
      "tensor([[[[-0.0834,    -inf,    -inf,    -inf],\n",
      "          [-0.0686, -0.0825,    -inf,    -inf],\n",
      "          [-0.0881, -0.0991, -0.1975,    -inf],\n",
      "          [-0.0862, -0.1245, -0.2875, -0.2431]],\n",
      "\n",
      "         [[ 0.2568,    -inf,    -inf,    -inf],\n",
      "          [ 0.2862,  0.2572,    -inf,    -inf],\n",
      "          [ 0.4133,  0.3764,  0.2460,    -inf],\n",
      "          [ 0.1937,  0.1318, -0.0408,  0.1696]],\n",
      "\n",
      "         [[ 0.0255,    -inf,    -inf,    -inf],\n",
      "          [-0.0236,  0.0309,    -inf,    -inf],\n",
      "          [-0.0040,  0.0678,  0.1092,    -inf],\n",
      "          [ 0.0426,  0.0868,  0.1742, -0.0161]]],\n",
      "\n",
      "\n",
      "        [[[-0.0673,    -inf,    -inf,    -inf],\n",
      "          [-0.1612, -0.0941,    -inf,    -inf],\n",
      "          [-0.1624, -0.1452, -0.2296,    -inf],\n",
      "          [-0.1657, -0.0959, -0.1652, -0.2055]],\n",
      "\n",
      "         [[ 0.1737,    -inf,    -inf,    -inf],\n",
      "          [-0.0108,  0.1578,    -inf,    -inf],\n",
      "          [ 0.1431,  0.3786,  0.2496,    -inf],\n",
      "          [ 0.1366,  0.3855,  0.1901,  0.3699]],\n",
      "\n",
      "         [[ 0.0664,    -inf,    -inf,    -inf],\n",
      "          [ 0.0810, -0.0390,    -inf,    -inf],\n",
      "          [ 0.0849, -0.0734,  0.0410,    -inf],\n",
      "          [ 0.1631, -0.0337,  0.0723,  0.0098]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5035, 0.4965, 0.0000, 0.0000],\n",
      "          [0.3466, 0.3428, 0.3107, 0.0000],\n",
      "          [0.2751, 0.2648, 0.2250, 0.2352]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5073, 0.4927, 0.0000, 0.0000],\n",
      "          [0.3559, 0.3430, 0.3011, 0.0000],\n",
      "          [0.2698, 0.2536, 0.2134, 0.2633]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4864, 0.5136, 0.0000, 0.0000],\n",
      "          [0.3131, 0.3364, 0.3506, 0.0000],\n",
      "          [0.2422, 0.2531, 0.2763, 0.2284]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4832, 0.5168, 0.0000, 0.0000],\n",
      "          [0.3387, 0.3446, 0.3167, 0.0000],\n",
      "          [0.2479, 0.2658, 0.2480, 0.2382]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4579, 0.5421, 0.0000, 0.0000],\n",
      "          [0.2960, 0.3746, 0.3293, 0.0000],\n",
      "          [0.2174, 0.2788, 0.2293, 0.2745]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5300, 0.4700, 0.0000, 0.0000],\n",
      "          [0.3558, 0.3037, 0.3405, 0.0000],\n",
      "          [0.2784, 0.2286, 0.2542, 0.2388]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0998,  0.0088, -0.2239,  0.0868, -0.4007, -0.0979,  0.5699,\n",
       "          -0.2157,  0.0259,  0.2374, -0.0623, -0.3742,  0.1215, -0.3384,\n",
       "          -0.3979],\n",
       "         [-0.0518,  0.0212, -0.1555,  0.0111, -0.3704, -0.1655,  0.5500,\n",
       "          -0.2036, -0.0059,  0.1552, -0.1609, -0.3379,  0.1518, -0.2935,\n",
       "          -0.3778],\n",
       "         [ 0.1753, -0.2545, -0.0684,  0.0714, -0.2857,  0.2374,  0.0751,\n",
       "          -0.1218,  0.2345,  0.0125, -0.2632, -0.1939, -0.0456, -0.3247,\n",
       "          -0.3117],\n",
       "         [ 0.2450, -0.2002, -0.0748, -0.0008, -0.2626,  0.1804, -0.0265,\n",
       "          -0.0452,  0.2256, -0.0400, -0.3293, -0.2018, -0.0606, -0.2342,\n",
       "          -0.1655]],\n",
       "\n",
       "        [[ 0.3797, -0.6368, -0.1588,  0.0027, -0.3756,  0.4985, -0.2552,\n",
       "          -0.0759,  0.2512, -0.3902, -0.2752,  0.1731,  0.0134, -0.3697,\n",
       "          -0.3246],\n",
       "         [ 0.2548, -0.0706, -0.1386, -0.1202, -0.2569,  0.0901,  0.0898,\n",
       "           0.0363,  0.1339,  0.0278, -0.2490, -0.2191,  0.0837, -0.2117,\n",
       "          -0.2002],\n",
       "         [ 0.2421, -0.3768, -0.0973,  0.0269, -0.3111,  0.3094, -0.1324,\n",
       "          -0.0541,  0.2253, -0.1690, -0.3182, -0.0912, -0.0841, -0.2038,\n",
       "          -0.2378],\n",
       "         [ 0.1064, -0.1678, -0.1426,  0.1725, -0.4742, -0.2968,  0.5072,\n",
       "          -0.3481,  0.0331,  0.1520, -0.3000, -0.4309, -0.0632, -0.2805,\n",
       "          -0.2103]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.tril(torch.ones(4, 4))\n",
    "x = torch.rand(2, 4 ,15)\n",
    "a = MultiHeadAttention(15, 3)\n",
    "a(x,x,x, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model ,dropout):\n",
    "\n",
    "        super(ResidualConnection, self).__init__()\n",
    "        self.ln = LayerNormalization()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        return self.ln(x1 + self.dropout(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self,  dff, d_model, heads, dropout):\n",
    "\n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        self.multi_attention = MutltiHeadAttention(d_model, heads, dropout)\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(d_model, dropout) for _ in range(2)])\n",
    "\n",
    "        self.feed_forward = FeedForward(d_model, dff)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x1, key, value = self.multi_attention(x, x, x)\n",
    "        x2 = self.residual_connections[0](x, x1)\n",
    "        x3 = self.feed_forward(x2)\n",
    "        x4 = self.residual_connections[1](x2, x3)\n",
    "        return x4, key, value\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, dff, seq_length, d_model, heads,dropout, n = 6):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding_layer = InputEmbedding(d_model, vocab_size)\n",
    "        self.positional_embedding = PositionalEmbedding(d_model, seq_length, dropout)\n",
    "        \n",
    "        self.encoder_blocks = nn.ModuleList([EncoderBlock(dff, d_model, heads,dropout) for _ in range(n)])\n",
    "        print(type(self.encoder_blocks))\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.positional_embedding(self.embedding_layer(x))\n",
    "\n",
    "        for block in self.encoder_blocks:\n",
    "            x, key, value = block(x)\n",
    "        return x, key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.container.ModuleList'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder_blocks): ModuleList(\n",
       "    (0-5): 6 x EncoderBlock()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder(0, 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dff, d_model, heads, dropout):\n",
    "\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        # self.masked_attention = masked_attention\n",
    "        # self.residual_connections = residual_connections\n",
    "        # self.cross_attention = cross_attention\n",
    "        # self.feed_forward = feed_forward\n",
    "        self.masked_attention = MultiHeadAttention(d_model, heads)\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(d_model, dropout) for _ in range(3)])\n",
    "        self.cross_attention = MultiHeadAttention(d_model, heads)\n",
    "        self.feed_forward = FeedForward(d_model, dff)\n",
    "\n",
    "\n",
    "    def forward(self, x, key, value, mask):\n",
    "\n",
    "        x1, _, _ = self.masked_attention(x, x, x, mask)\n",
    "        x2 = self.residual_connections[0](x, x1)\n",
    "\n",
    "        x3, _, _ = self.cross_attention(x2, key, value)\n",
    "        x4 = self.residual_connections[1](x2, x3)\n",
    "\n",
    "        x5 = self.feed_forward(x4)\n",
    "        x6 = self.residual_connections[2](x4, x5)\n",
    "\n",
    "        return x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, dff, seq_length, d_model, heads,dropout, n = 6):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.embedding_layer = InputEmbedding(d_model, vocab_size)\n",
    "        self.positional_embedding = PositionalEmbedding(d_model, seq_length, dropout)\n",
    "\n",
    "        self.decoder_blocks = nn.ModuleList([DecoderBlock(dff, d_model, heads,dropout) for _ in range(n)])\n",
    "\n",
    "        self.mask = m = torch.tril(torch.ones(seq_length, seq_length))\n",
    "\n",
    "\n",
    "    def forward(self, x, key, value):\n",
    "\n",
    "        x = self.positional_embedding(self.embedding_layer(x))\n",
    "        for block in self.decoder_blocks:\n",
    "            x = block(x, key, value, self.mask)\n",
    "        return x            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = torch.rand((4, 3, 3))\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = nn.Softmax(dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2745, 0.2622, 0.7498, 0.2155],\n",
       "        [0.2069, 0.7540, 0.0982, 0.3528],\n",
       "        [0.9714, 0.7038, 0.2820, 0.3485],\n",
       "        [0.0767, 0.5571, 0.3614, 0.1596],\n",
       "        [0.7256, 0.7579, 0.5823, 0.4380]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(4, 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9769, 0.1334, 0.0875, 0.5955, 0.2906, 0.4639],\n",
       "         [0.8240, 0.0231, 0.4150, 0.5795, 0.7420, 0.0552],\n",
       "         [0.1538, 0.9790, 0.6506, 0.7592, 0.7137, 0.3978],\n",
       "         [0.6863, 0.1378, 0.6559, 0.1667, 0.4780, 0.3286],\n",
       "         [0.6324, 0.0663, 0.9344, 0.9531, 0.6710, 0.2322]],\n",
       "\n",
       "        [[0.9834, 0.8209, 0.3834, 0.4204, 0.7666, 0.2699],\n",
       "         [0.8639, 0.9251, 0.1020, 0.7359, 0.0199, 0.7547],\n",
       "         [0.9273, 0.0284, 0.5178, 0.3728, 0.7439, 0.7334],\n",
       "         [0.8518, 0.1130, 0.4126, 0.9243, 0.6957, 0.1537],\n",
       "         [0.1205, 0.7821, 0.1062, 0.3711, 0.2527, 0.8687]],\n",
       "\n",
       "        [[0.9578, 0.2201, 0.6164, 0.9399, 0.6242, 0.7545],\n",
       "         [0.2806, 0.1959, 0.0043, 0.7410, 0.7151, 0.9750],\n",
       "         [0.9442, 0.6250, 0.2752, 0.1552, 0.1160, 0.8005],\n",
       "         [0.6515, 0.2737, 0.6172, 0.1177, 0.4433, 0.2350],\n",
       "         [0.9038, 0.8049, 0.6357, 0.6561, 0.6560, 0.4586]],\n",
       "\n",
       "        [[0.9834, 0.7357, 0.0055, 0.8204, 0.5147, 0.9410],\n",
       "         [0.4765, 0.5496, 0.3550, 0.5732, 0.2556, 0.2776],\n",
       "         [0.9525, 0.9659, 0.4586, 0.8258, 0.5041, 0.2691],\n",
       "         [0.0142, 0.0694, 0.8576, 0.8526, 0.4560, 0.8011],\n",
       "         [0.8525, 0.6264, 0.7737, 0.7134, 0.1510, 0.9719]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.view(4, 5, 2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9769, 0.1334, 0.0875],\n",
       "          [0.8240, 0.0231, 0.4150],\n",
       "          [0.1538, 0.9790, 0.6506],\n",
       "          [0.6863, 0.1378, 0.6559],\n",
       "          [0.6324, 0.0663, 0.9344]],\n",
       "\n",
       "         [[0.5955, 0.2906, 0.4639],\n",
       "          [0.5795, 0.7420, 0.0552],\n",
       "          [0.7592, 0.7137, 0.3978],\n",
       "          [0.1667, 0.4780, 0.3286],\n",
       "          [0.9531, 0.6710, 0.2322]]],\n",
       "\n",
       "\n",
       "        [[[0.9834, 0.8209, 0.3834],\n",
       "          [0.8639, 0.9251, 0.1020],\n",
       "          [0.9273, 0.0284, 0.5178],\n",
       "          [0.8518, 0.1130, 0.4126],\n",
       "          [0.1205, 0.7821, 0.1062]],\n",
       "\n",
       "         [[0.4204, 0.7666, 0.2699],\n",
       "          [0.7359, 0.0199, 0.7547],\n",
       "          [0.3728, 0.7439, 0.7334],\n",
       "          [0.9243, 0.6957, 0.1537],\n",
       "          [0.3711, 0.2527, 0.8687]]],\n",
       "\n",
       "\n",
       "        [[[0.9578, 0.2201, 0.6164],\n",
       "          [0.2806, 0.1959, 0.0043],\n",
       "          [0.9442, 0.6250, 0.2752],\n",
       "          [0.6515, 0.2737, 0.6172],\n",
       "          [0.9038, 0.8049, 0.6357]],\n",
       "\n",
       "         [[0.9399, 0.6242, 0.7545],\n",
       "          [0.7410, 0.7151, 0.9750],\n",
       "          [0.1552, 0.1160, 0.8005],\n",
       "          [0.1177, 0.4433, 0.2350],\n",
       "          [0.6561, 0.6560, 0.4586]]],\n",
       "\n",
       "\n",
       "        [[[0.9834, 0.7357, 0.0055],\n",
       "          [0.4765, 0.5496, 0.3550],\n",
       "          [0.9525, 0.9659, 0.4586],\n",
       "          [0.0142, 0.0694, 0.8576],\n",
       "          [0.8525, 0.6264, 0.7737]],\n",
       "\n",
       "         [[0.8204, 0.5147, 0.9410],\n",
       "          [0.5732, 0.2556, 0.2776],\n",
       "          [0.8258, 0.5041, 0.2691],\n",
       "          [0.8526, 0.4560, 0.8011],\n",
       "          [0.7134, 0.1510, 0.9719]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
