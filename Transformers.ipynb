{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport math\nfrom tqdm import tqdm","metadata":{"_uuid":"11508b98-e27c-4b5d-b420-be615ef40b32","_cell_guid":"f14ea6d8-199c-4516-a59e-e50b49548d67","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:03.867462Z","iopub.execute_input":"2025-07-09T08:26:03.867713Z","iopub.status.idle":"2025-07-09T08:26:04.883894Z","shell.execute_reply.started":"2025-07-09T08:26:03.867691Z","shell.execute_reply":"2025-07-09T08:26:04.882913Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\nfrom torch.functional import F","metadata":{"_uuid":"bde5996b-7cf6-4663-a6f6-a8c62aba182a","_cell_guid":"d75d1ad9-fb3e-46f3-a94c-9d400e18083a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:04.884786Z","iopub.execute_input":"2025-07-09T08:26:04.885258Z","iopub.status.idle":"2025-07-09T08:26:08.270424Z","shell.execute_reply.started":"2025-07-09T08:26:04.885209Z","shell.execute_reply":"2025-07-09T08:26:08.269452Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class InputEmbedding(nn.Module):\n\n    def __init__(self, d_model, vocab_size):\n        super().__init__()\n        self.d_model = d_model\n        self.vocab_size = vocab_size\n        self.embedding = nn.Embedding(vocab_size, d_model)\n        # shape = [num of words * dimension of embedding layer]\n\n    def forward(self, x):\n        # return self.embedding(x)\n        return self.embedding(x) * math.sqrt(self.d_model)\n        # dimension same","metadata":{"_uuid":"24594a5b-01e1-4a8e-9a10-a69d504d4dd4","_cell_guid":"39758ef2-bba0-4d81-b59b-9e3193189397","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:08.271455Z","iopub.execute_input":"2025-07-09T08:26:08.271915Z","iopub.status.idle":"2025-07-09T08:26:08.277023Z","shell.execute_reply.started":"2025-07-09T08:26:08.271878Z","shell.execute_reply":"2025-07-09T08:26:08.276171Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model, seq_length, device,dropout = 0.1):\n        super().__init__()\n        self.d_model = d_model\n        self.seq_length = seq_length\n        self.dropout = nn.Dropout(dropout)\n        \n        # print(self.seq_length)\n        pe = torch.zeros(self.seq_length, self.d_model)  # To get the matrix of dimension as of embedding layer\n        positions = torch.arange(0, self.seq_length, dtype = torch.float).unsqueeze(1)  # matrix of [seq_length x 1]\n        \n        # div_term = (positions * (torch.pow(10000, 2 * torch.arange(0, d_model, 2).float() /self.d_model))) #to calculate say (angle)  pos/(10000^(2i/dmodel))\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(positions * div_term)   #Apply sine formula in even positions\n        pe[:, 1::2] = torch.cos(positions * div_term)   # Appply cosine formula in odd positions\n        \n        pe = pe.unsqueeze(0)  # for batches dimension [1 x seq_length x d_model]\n\n        self.register_buffer('pe', pe) # By adding this in register buffer this stores pe too while saving the model without considering it as a learning parameter\n                \n\n    def forward(self, x):\n        x = x + self.pe[:, :x.shape[1], :].requires_grad_(False)  #To make it not to learn\n        return self.dropout(x)","metadata":{"_uuid":"e5b71043-96a7-4106-8a46-447e8c5d32f9","_cell_guid":"f945c7bc-c9b0-4635-a76d-e2acc35de7f8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:08.278168Z","iopub.execute_input":"2025-07-09T08:26:08.278495Z","iopub.status.idle":"2025-07-09T08:26:08.301115Z","shell.execute_reply.started":"2025-07-09T08:26:08.278464Z","shell.execute_reply":"2025-07-09T08:26:08.300193Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# class LayerNormalization(nn.Module):\n#     def __init__(self, d_model,epsilon=1e-5):\n#         super(LayerNormalization, self).__init__()\n#         self.epsilon = epsilon\n#         self.gamma = nn.Parameter(torch.ones(d_model))  # Scale\n#         self.beta = nn.Parameter(torch.zeros(d_model))  # Shift\n\n#     def forward(self, x):\n#         mean = x.mean(dim=-1, keepdim=True)\n#         std = x.std(dim=-1, keepdim=True, unbiased = False) \n#         return self.gamma * (x - mean) / (std + self.epsilon) + self.beta","metadata":{"_uuid":"24d896d5-0f21-477a-a8c0-c20eb2154ecd","_cell_guid":"330715b6-f7b9-4272-99cd-204a8a7378dd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:08.302069Z","iopub.execute_input":"2025-07-09T08:26:08.302401Z","iopub.status.idle":"2025-07-09T08:26:08.319699Z","shell.execute_reply.started":"2025-07-09T08:26:08.302373Z","shell.execute_reply":"2025-07-09T08:26:08.318699Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class FeedForward(nn.Module):\n\n    def __init__(self, d_model, dff, dropout = 0.1):\n        super(FeedForward, self).__init__()\n        self.forward1 = nn.Linear(d_model, dff)\n        self.dropout = nn.Dropout(dropout)\n        self.forward2 = nn.Linear(dff, d_model)\n\n    def forward(self, x):\n        return self.forward2(self.dropout(torch.relu(self.forward1(x))))","metadata":{"_uuid":"46a5985a-4bd2-4357-bb2c-3c0950aa7787","_cell_guid":"98bd8781-94a0-41e1-bbfc-30798b09cbe6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:08.322362Z","iopub.execute_input":"2025-07-09T08:26:08.322632Z","iopub.status.idle":"2025-07-09T08:26:08.335222Z","shell.execute_reply.started":"2025-07-09T08:26:08.322610Z","shell.execute_reply":"2025-07-09T08:26:08.334225Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n\n    def __init__(self, d_model, heads, device,dropout = 0.1):\n        super(MultiHeadAttention, self).__init__()\n        self.d_model = d_model\n        self.heads = heads\n        self.d_heads = d_model//heads\n        self.device = device\n\n        self.w_q = nn.Linear(d_model, d_model)\n        self.w_v = nn.Linear(d_model, d_model)\n        self.w_k = nn.Linear(d_model, d_model)\n        self.w_o = nn.Linear(d_model, d_model)\n\n        self.softmax = nn.Softmax(dim = -1)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x_q, x_k, x_v, mask = None):\n        \n        batch_size, seq_len, d_model = x_q.shape\n        # print(x_q.shape, x_k.shape, x_v.shape)\n        query = self.w_q(x_q).view(batch_size, x_q.shape[1], self.heads, self.d_heads).permute(0, 2, 1, 3)\n        key = self.w_k(x_k).view(batch_size, x_k.shape[1], self.heads, self.d_heads).permute(0, 2, 1, 3)\n        value = self.w_v(x_v).view(batch_size, x_v.shape[1], self.heads, self.d_heads).permute(0, 2, 1, 3)\n\n        similarity = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_heads)\n        # print(similarity.shape)\n        if mask is not None:\n            # print(mask.shape, similarity.shape)\n            # mask = mask.to(self.device)\n            # print(mask.shape)\n            similarity = similarity.masked_fill(~mask.bool() , float('-inf'))\n        sim = F.softmax(similarity, dim = -1)\n        # print(f\"x_q \\t: {x_q.shape}\\nx_k \\t: {x_k.shape}\\nx_v \\t: {x_v.shape}\\nquery \\t: {query.shape}\\nkey \\t: {key.shape}\\nvalue \\t: {value.shape}\\nsimilarity \\t: {similarity.shape}\\nsim \\t: {sim.shape}\")\n        # print(sim.shape, value.shape)\n        final = torch.matmul(sim, value)\n        final = self.dropout(final)\n\n        final = final.permute(0, 2, 1, 3).contiguous()\n        final = final.view(batch_size, seq_len, self.d_model)\n        \n\n        return self.w_o(final)","metadata":{"_uuid":"5c87cc4f-2d94-437e-831a-dc5d7626ea93","_cell_guid":"ea46fdfc-c9f6-4fe4-a120-4033655d6e9a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:08.336783Z","iopub.execute_input":"2025-07-09T08:26:08.337051Z","iopub.status.idle":"2025-07-09T08:26:08.354743Z","shell.execute_reply.started":"2025-07-09T08:26:08.337029Z","shell.execute_reply":"2025-07-09T08:26:08.353719Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class ResidualConnection(nn.Module):\n\n    def __init__(self, d_model ,dropout):\n\n        super(ResidualConnection, self).__init__()\n        self.ln = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x1, x2):\n\n        return x1 + self.dropout(self.ln(x2))","metadata":{"_uuid":"3a45d0c4-cb12-47ba-b88d-0895501dd5d1","_cell_guid":"30afd5da-4f35-4300-9d07-1ad24c37be9a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:08.355776Z","iopub.execute_input":"2025-07-09T08:26:08.356199Z","iopub.status.idle":"2025-07-09T08:26:08.372182Z","shell.execute_reply.started":"2025-07-09T08:26:08.356167Z","shell.execute_reply":"2025-07-09T08:26:08.371287Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n\n    def __init__(self,  dff, d_model, heads, device,dropout):\n\n        super(EncoderBlock, self).__init__()\n        self.multi_attention = MultiHeadAttention(d_model, heads, device,dropout)\n        self.residual_connections = nn.ModuleList([ResidualConnection(d_model, dropout) for _ in range(2)])\n\n        self.feed_forward = FeedForward(d_model, dff)\n\n    def forward(self, x, mask):\n\n        x1 = self.multi_attention(x, x, x, mask)\n        x2 = self.residual_connections[0](x, x1)\n        x3 = self.feed_forward(x2)\n        x4 = self.residual_connections[1](x2, x3)\n        return x4","metadata":{"_uuid":"75ed6937-b617-4f13-b727-114a3aeaa416","_cell_guid":"f2aa9b42-53f0-4494-afa9-eb935d6cb750","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:08.372998Z","iopub.execute_input":"2025-07-09T08:26:08.373294Z","iopub.status.idle":"2025-07-09T08:26:08.388929Z","shell.execute_reply.started":"2025-07-09T08:26:08.373233Z","shell.execute_reply":"2025-07-09T08:26:08.387967Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class Encoder(nn.Module):\n\n    def __init__(self, vocab_size, dff, seq_length, d_model, heads,device, dropout, n = 6):\n\n        super(Encoder, self).__init__()\n\n        self.embedding_layer = InputEmbedding(d_model, vocab_size)\n        self.positional_encoding = PositionalEncoding(d_model, seq_length, device,dropout)\n        \n        self.encoder_blocks = nn.ModuleList([EncoderBlock(dff, d_model, heads,device,dropout) for _ in range(n)])\n\n    def forward(self,x_e):\n\n        x = self.positional_encoding(self.embedding_layer(x_e))\n        self.mask = (x_e != 0).long().unsqueeze(1).unsqueeze(2)\n        # print(self.mask.shape)\n        for block in self.encoder_blocks:\n            x = block(x, self.mask)\n        return x, self.mask","metadata":{"_uuid":"626b9766-7aa2-43a5-a126-b818e0e283f7","_cell_guid":"795efd59-a94b-4182-9da4-b5bd990521a2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:08.389831Z","iopub.execute_input":"2025-07-09T08:26:08.390134Z","iopub.status.idle":"2025-07-09T08:26:08.399209Z","shell.execute_reply.started":"2025-07-09T08:26:08.390104Z","shell.execute_reply":"2025-07-09T08:26:08.398384Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n\n    def __init__(self, dff, d_model, heads, device,dropout):\n\n        super(DecoderBlock, self).__init__()\n        \n        self.masked_attention = MultiHeadAttention(d_model, heads, device, dropout)\n        self.residual_connections = nn.ModuleList([ResidualConnection(d_model, dropout) for _ in range(3)])\n        self.cross_attention = MultiHeadAttention(d_model, heads, device, dropout)\n        self.feed_forward = FeedForward(d_model, dff)\n\n\n    def forward(self, x, x_enc, tgt_mask, src_mask):\n        # print(x.shape, x_enc.shape)\n        # print('here3')\n\n\n\n        x1= self.masked_attention(x, x, x, tgt_mask)\n        x2 = self.residual_connections[0](x, x1)\n\n        x3= self.cross_attention(x2, x_enc, x_enc, src_mask)\n        x4 = self.residual_connections[1](x2, x3)\n\n        x5 = self.feed_forward(x4)\n        x6 = self.residual_connections[2](x4, x5)\n\n        return x6","metadata":{"_uuid":"d97fcc5d-6a54-471e-941d-1f843816d6ae","_cell_guid":"6fb03e86-b6ce-4b4b-a702-ee054a1c1bcb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:08.400059Z","iopub.execute_input":"2025-07-09T08:26:08.400411Z","iopub.status.idle":"2025-07-09T08:26:08.416363Z","shell.execute_reply.started":"2025-07-09T08:26:08.400382Z","shell.execute_reply":"2025-07-09T08:26:08.415462Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class Decoder(nn.Module):\n\n    def __init__(self, vocab_size, dff, seq_length, d_model, heads,device ,dropout, n = 6):\n\n        super(Decoder, self).__init__()\n        \n        self.embedding_layer = InputEmbedding(d_model, vocab_size)\n        self.positional_encoding = PositionalEncoding(d_model, seq_length, device,dropout)\n\n        self.decoder_blocks = nn.ModuleList([DecoderBlock(dff, d_model, heads,device, dropout) for _ in range(n)])\n\n        self.register_buffer(\"casual_mask\", torch.tril(torch.ones(seq_length, seq_length)))\n        self.linear = nn.Linear(d_model, vocab_size)\n        # print('decoder')/\n\n\n    def forward(self, x_d, x_enc, src_mask = None, tgt_mask = None):\n        # print('here1')\n        if src_mask is None:\n            src_mask = (x_d != 0).unsqueeze(1).unsqueeze(2) \n            casual_mask = self.casual_mask[:x_d.shape[1], :x_d.shape[1]].unsqueeze(0).unsqueeze(0)\n            tgt_mask = src_mask.bool() & casual_mask.bool()\n  \n        x = self.positional_encoding(self.embedding_layer(x_d))\n\n        # print(f\"Mask : \", self.mask1.shape, self.mask2, self.mask2.shape)\n        for block in self.decoder_blocks:\n            # print('here2')\n            x = block(x, x_enc, tgt_mask.long(), src_mask.long())\n            # print(self.mask)\n            # print('here')\n        return (self.linear(x))","metadata":{"_uuid":"bc0db8fb-99e8-49ae-82aa-1c1b50c8cec6","_cell_guid":"8f881a23-4626-4a9a-aff5-17a1ff7449bf","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:08.417490Z","iopub.execute_input":"2025-07-09T08:26:08.417725Z","iopub.status.idle":"2025-07-09T08:26:08.437849Z","shell.execute_reply.started":"2025-07-09T08:26:08.417706Z","shell.execute_reply":"2025-07-09T08:26:08.437035Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class MyTransformer(nn.Module):\n\n    def __init__(self, vocab_size_source, vocab_size_target, seq_length_source, seq_length_target, device,d_model = 512, heads = 8, dropout = 0.1, dff = 2048):\n\n        super(MyTransformer, self).__init__()\n\n        self.encoder = Encoder(vocab_size_source, dff, seq_length_source, d_model, heads, device, dropout)\n        # print(1)\n        self.decoder = Decoder(vocab_size_target, dff, seq_length_target, d_model, heads, device, dropout)\n\n        # for parameter in self.parameters():\n        #     if isinstance(parameter, nn.Linear):\n        #         nn.init.xavier_uniform_(parameter)\n\n    def forward(self, x_in, x_op=None):\n        # print('here')\n        x_enc, src_mask = self.encoder(x_in)\n        \n        if x_op is None:\n            return x_enc, src_mask\n            \n        output = self.decoder(x_op, x_enc)\n        return output","metadata":{"_uuid":"2c175931-ef77-469b-983e-891dac44e781","_cell_guid":"768d5f4d-a98e-4056-8d03-720e9776c534","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:08.438853Z","iopub.execute_input":"2025-07-09T08:26:08.439233Z","iopub.status.idle":"2025-07-09T08:26:08.459014Z","shell.execute_reply.started":"2025-07-09T08:26:08.439203Z","shell.execute_reply":"2025-07-09T08:26:08.458117Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from datasets import load_dataset\nimport string\nimport nltk\nfrom collections import Counter\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nnltk_dir = r'/kaggle/working/'\nnltk.download('stopwords', download_dir = nltk_dir)\nnltk.download('wordnet', download_dir = nltk_dir)\nnltk.download('punkt', download_dir = nltk_dir)\nnltk.data.path.append('/kaggle/working/')\n# nltk.download('punkt')\n# nltk.download('stopwords')\n# nltk.download('wordnet')","metadata":{"_uuid":"a4e9b8df-31ea-49a2-8f86-31f1d1722d25","_cell_guid":"523b4380-8bde-42ed-8d4b-8067f763f70b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:08.459932Z","iopub.execute_input":"2025-07-09T08:26:08.460267Z","iopub.status.idle":"2025-07-09T08:26:11.477186Z","shell.execute_reply.started":"2025-07-09T08:26:08.460239Z","shell.execute_reply":"2025-07-09T08:26:11.476196Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /kaggle/working/...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package wordnet to /kaggle/working/...\n[nltk_data] Downloading package punkt to /kaggle/working/...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"dataset = load_dataset(\"Helsinki-NLP/opus_books\", 'en-es')\ndfff = dataset['train'].to_pandas()\ndfff = dfff['translation']\ndf = pd.DataFrame(dfff.to_list())[:40000]\n\ndf['len1'] = df['en'].apply(lambda x : len(x.split()))\ndf['len2'] = df['es'].apply(lambda x : len(x.split()))\ndf = df[(df['len1'] >5) & (df['len1'] <100) & (df['len2'] >5) & (df['len2'] <100)]","metadata":{"_uuid":"9fab0899-8125-4ae9-94e2-94b3af8a8618","_cell_guid":"dc7c9fb6-e45f-442e-985d-b759bcae3985","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:11.478050Z","iopub.execute_input":"2025-07-09T08:26:11.478593Z","iopub.status.idle":"2025-07-09T08:26:17.341250Z","shell.execute_reply.started":"2025-07-09T08:26:11.478558Z","shell.execute_reply":"2025-07-09T08:26:17.340519Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a8b8c2a6ff4f8eb51d1cf4fa1613ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/16.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73ba3b4b71ae42e68717ae8cf89b8bd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/93470 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d94fabaa439a4963b6ca0cb6d45b2581"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"df.head()","metadata":{"_uuid":"bf4ccfae-1b37-4de3-94d6-3ee141730621","_cell_guid":"0dcb7e2d-fa70-4fa4-89a9-4190d3712255","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:17.341985Z","iopub.execute_input":"2025-07-09T08:26:17.342265Z","iopub.status.idle":"2025-07-09T08:26:17.360333Z","shell.execute_reply.started":"2025-07-09T08:26:17.342243Z","shell.execute_reply":"2025-07-09T08:26:17.359564Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                  en  \\\n4  The family of Dashwood had long been settled i...   \n5  Their estate was large, and their residence wa...   \n6  The late owner of this estate was a single man...   \n7  But her death, which happened ten years before...   \n8  In the society of his nephew and niece, and th...   \n\n                                                  es  len1  len2  \n4  La familia Dashwood llevaba largo tiempo afinc...    10     9  \n5  Su propiedad era de buen tamaño, y en el centr...    40    41  \n6  El último dueño de esta propiedad había sido u...    34    36  \n7  Pero la muerte de ella, ocurrida diez años ant...    54    56  \n8  En compañía de su sobrino y sobrina, y de los ...    18    21  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>es</th>\n      <th>len1</th>\n      <th>len2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>The family of Dashwood had long been settled i...</td>\n      <td>La familia Dashwood llevaba largo tiempo afinc...</td>\n      <td>10</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Their estate was large, and their residence wa...</td>\n      <td>Su propiedad era de buen tamaño, y en el centr...</td>\n      <td>40</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The late owner of this estate was a single man...</td>\n      <td>El último dueño de esta propiedad había sido u...</td>\n      <td>34</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>But her death, which happened ten years before...</td>\n      <td>Pero la muerte de ella, ocurrida diez años ant...</td>\n      <td>54</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>In the society of his nephew and niece, and th...</td>\n      <td>En compañía de su sobrino y sobrina, y de los ...</td>\n      <td>18</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# max(df['len2'])","metadata":{"_uuid":"de8c5363-03d3-4ede-a59f-d7ba07539def","_cell_guid":"ba8d6cc4-5165-4450-86a3-ed549eeec2b0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:17.361162Z","iopub.execute_input":"2025-07-09T08:26:17.361377Z","iopub.status.idle":"2025-07-09T08:26:17.364861Z","shell.execute_reply.started":"2025-07-09T08:26:17.361359Z","shell.execute_reply":"2025-07-09T08:26:17.364026Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"\nX_token = [text for tokens in df['en'] for text in tokens.split()]\nc = Counter(X_token)","metadata":{"_uuid":"d558dd16-ef6d-4814-8974-b5fd34277092","_cell_guid":"b99af3f5-6c8d-4a66-b28b-a473fd7ac5f8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:17.365628Z","iopub.execute_input":"2025-07-09T08:26:17.365814Z","iopub.status.idle":"2025-07-09T08:26:17.601706Z","shell.execute_reply.started":"2025-07-09T08:26:17.365797Z","shell.execute_reply":"2025-07-09T08:26:17.600861Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"len(c)","metadata":{"_uuid":"871daeb9-e8c9-4d1a-8bdf-fdb7af46b3e1","_cell_guid":"640c4395-4980-4a47-a212-2f6e236bbe77","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:17.602544Z","iopub.execute_input":"2025-07-09T08:26:17.602753Z","iopub.status.idle":"2025-07-09T08:26:17.620673Z","shell.execute_reply.started":"2025-07-09T08:26:17.602735Z","shell.execute_reply":"2025-07-09T08:26:17.619857Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"70025"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"len(df)","metadata":{"_uuid":"6295f8f2-e6b8-4374-8c19-268e08cd433f","_cell_guid":"da0c44a3-5184-44ea-bf58-1de249c0ac92","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:17.623673Z","iopub.execute_input":"2025-07-09T08:26:17.623892Z","iopub.status.idle":"2025-07-09T08:26:17.637980Z","shell.execute_reply.started":"2025-07-09T08:26:17.623874Z","shell.execute_reply":"2025-07-09T08:26:17.637343Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"32814"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"len(df)","metadata":{"_uuid":"c5a92c68-87ac-4edc-8ecc-3f7ce262777e","_cell_guid":"85ed930d-ac56-4d37-99c8-6521e893a51d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:17.639165Z","iopub.execute_input":"2025-07-09T08:26:17.639418Z","iopub.status.idle":"2025-07-09T08:26:17.652918Z","shell.execute_reply.started":"2025-07-09T08:26:17.639399Z","shell.execute_reply":"2025-07-09T08:26:17.652065Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"32814"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"\nimport sentencepiece as spm\n\nclass PreprocessText(nn.Module):\n\n    def __init__(self, df, vocab_size=8000, model_prefix=\"bpe\"):\n        super(PreprocessText, self).__init__()\n        self.df = df\n        self.vocab_size = vocab_size\n        self.model_prefix = model_prefix\n\n        self.pad_id = 0\n        self.unk_id = 1\n        self.bos_id = 2\n        self.eos_id = 3\n\n        # Train BPE tokenizer\n        self.train_bpe()\n\n        # Load trained tokenizer\n        self.sp_en = spm.SentencePieceProcessor(model_file=f\"{model_prefix}_en.model\")\n        self.sp_es = spm.SentencePieceProcessor(model_file=f\"{model_prefix}_es.model\")\n\n    def train_bpe(self):\n        \"\"\"Train BPE model for both languages using SentencePiece\"\"\"\n        with open(\"en_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n            f.write(\"\\n\".join(self.df['en'].astype(str).tolist()))\n\n        with open(\"es_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n            f.write(\"\\n\".join(self.df['es'].astype(str).tolist()))\n            \n        spm.SentencePieceTrainer.train(\n            input=\"en_corpus.txt\", \n            model_prefix=f\"{self.model_prefix}_en\",\n            vocab_size=self.vocab_size, \n            model_type=\"bpe\",\n            pad_id=self.pad_id,\n            unk_id=self.unk_id,\n            bos_id=self.bos_id,\n            eos_id=self.eos_id\n        )\n\n        spm.SentencePieceTrainer.train(\n            input=\"es_corpus.txt\",\n            model_prefix=f\"{self.model_prefix}_es\",\n            vocab_size=self.vocab_size,\n            model_type=\"bpe\",\n            pad_id=self.pad_id,\n            unk_id=self.unk_id,\n            bos_id=self.bos_id,\n            eos_id=self.eos_id\n        )\n\n    def tokenize_text(self, text, sp):\n        \"\"\"Tokenize using trained BPE model\"\"\"\n        text = text.lower()  \n        text = text.translate(str.maketrans('', '', string.punctuation))  \n        return sp.encode(text, out_type=str)\n\n    def build_vocab(self, sp):\n        \"\"\"Get the vocabulary dictionary from the trained BPE model\"\"\"\n        return {sp.id_to_piece(i): i for i in range(sp.get_piece_size())}\n\n\n    def text_to_sequence(self, tokens, vocab):\n        \"\"\"Convert tokens to sequence of indices\"\"\"\n        # tokens = ['<s>'] + tokens + ['</s>']\n        return [vocab.get(token, self.unk_id) for token in tokens]\n\n    def pad_sequences(self, seq, pad_index = 0):\n        \"\"\"Pad sequences to max_len\"\"\"\n        max_len = self.max_len - 2 \n        if len(seq) >= self.max_len:\n            seq = seq[:self.max_len]\n            return [self.bos_id] + seq + [self.eos_id]\n        paded = [self.bos_id] + seq + [self.eos_id] + [self.pad_id] *  (self.max_len - len(seq))\n        return paded\n            # return [2] + seq[:self.max_len] + [3]\n        # return [2] + seq + [3] + [pad_index] * (self.max_len - len(seq))\n        # return np.array(seq + [0] * (self.max_len - len(seq)) if len(seq) < self.max_len else seq[:self.max_len])\n\n    def build(self):\n        \"\"\"Preprocess text using BPE and return tensors for training\"\"\"\n        # Tokenize text\n        self.df['enn'] = self.df['en'].apply(lambda x: self.tokenize_text(x, self.sp_en))\n        self.df['ess'] = self.df['es'].apply(lambda x: self.tokenize_text(x, self.sp_es))\n\n        # Build vocab\n        self.en_vocab = self.build_vocab(self.sp_en)\n        self.es_vocab = self.build_vocab(self.sp_es)\n\n        # Convert to sequences\n        self.df['en_num'] = self.df['enn'].apply(lambda x: self.text_to_sequence(x, self.en_vocab))\n        self.df['es_num'] = self.df['ess'].apply(lambda x: self.text_to_sequence(x, self.es_vocab))\n\n        # Get max length\n        self.max_len = max(self.df['en_num'].apply(len).max() + 2, self.df['es_num'].apply(len).max() + 2)\n\n        # Pad sequences\n        pad_index_en = self.en_vocab['<pad>']\n        pad_index_es = self.es_vocab['<pad>']\n        \n        self.df['en_paded'] = self.df['en_num'].apply(lambda x : self.pad_sequences(x, pad_index_en))\n        self.df['es_paded'] = self.df['es_num'].apply(lambda x : self.pad_sequences(x, pad_index_es))\n\n        # Convert to tensors\n        X = torch.tensor(self.df['en_paded'].to_list(), dtype=torch.long)\n        y = torch.tensor(self.df['es_paded'].to_list(), dtype=torch.long)\n        \n        # Create training data\n        source = X[:, 1:]\n        target_ip = y[:, :-1]\n        target_op = y[:, 1:]\n\n        return self.df, source, target_ip, target_op, self.en_vocab, self.es_vocab, self.max_len + 2\n\n# Example usage:\npt = PreprocessText(df)\ndf, src, tgt_ip, tgt_op, en_vocab, es_vocab, max_len = pt.build()","metadata":{"_uuid":"d5e451c0-b19a-412c-a971-93f62e368807","_cell_guid":"5e5005fd-54b1-4644-9825-c1beed29f8ba","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:17.653753Z","iopub.execute_input":"2025-07-09T08:26:17.654001Z","iopub.status.idle":"2025-07-09T08:26:32.994852Z","shell.execute_reply.started":"2025-07-09T08:26:17.653982Z","shell.execute_reply":"2025-07-09T08:26:32.993898Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"max_len","metadata":{"_uuid":"2affeeff-4188-480b-b6bd-2b5cc5a0b5fd","_cell_guid":"742badb5-15de-4bd4-ae91-a1342838a0be","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:32.995784Z","iopub.execute_input":"2025-07-09T08:26:32.996093Z","iopub.status.idle":"2025-07-09T08:26:33.001137Z","shell.execute_reply.started":"2025-07-09T08:26:32.996050Z","shell.execute_reply":"2025-07-09T08:26:33.000499Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"161"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"print(df.iloc[0]['en'])","metadata":{"_uuid":"05798bc9-099e-474c-aca4-24fa081ce76e","_cell_guid":"8650ba18-a028-4c2b-a7b5-273413fd6404","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:33.001828Z","iopub.execute_input":"2025-07-09T08:26:33.002059Z","iopub.status.idle":"2025-07-09T08:26:33.015714Z","shell.execute_reply.started":"2025-07-09T08:26:33.002038Z","shell.execute_reply":"2025-07-09T08:26:33.014894Z"}},"outputs":[{"name":"stdout","text":"The family of Dashwood had long been settled in Sussex.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# (en_vocab)","metadata":{"_uuid":"6305f512-745c-4def-a850-a7abb72f18c4","_cell_guid":"3607100c-8bfa-4549-959f-a5d2f24dfaf6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:33.016463Z","iopub.execute_input":"2025-07-09T08:26:33.016766Z","iopub.status.idle":"2025-07-09T08:26:33.031750Z","shell.execute_reply.started":"2025-07-09T08:26:33.016746Z","shell.execute_reply":"2025-07-09T08:26:33.030838Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"df.head()","metadata":{"_uuid":"37b4319f-7c4a-46b1-9359-ca7f5e2bf131","_cell_guid":"cc1c5072-5d4a-4d4a-8873-1e989faafde4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:33.032581Z","iopub.execute_input":"2025-07-09T08:26:33.032878Z","iopub.status.idle":"2025-07-09T08:26:33.068478Z","shell.execute_reply.started":"2025-07-09T08:26:33.032851Z","shell.execute_reply":"2025-07-09T08:26:33.067488Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                                                  en  \\\n4  The family of Dashwood had long been settled i...   \n5  Their estate was large, and their residence wa...   \n6  The late owner of this estate was a single man...   \n7  But her death, which happened ten years before...   \n8  In the society of his nephew and niece, and th...   \n\n                                                  es  len1  len2  \\\n4  La familia Dashwood llevaba largo tiempo afinc...    10     9   \n5  Su propiedad era de buen tamaño, y en el centr...    40    41   \n6  El último dueño de esta propiedad había sido u...    34    36   \n7  Pero la muerte de ella, ocurrida diez años ant...    54    56   \n8  En compañía de su sobrino y sobrina, y de los ...    18    21   \n\n                                                 enn  \\\n4  [▁the, ▁family, ▁of, ▁d, ash, wood, ▁had, ▁lon...   \n5  [▁their, ▁estate, ▁was, ▁large, ▁and, ▁their, ...   \n6  [▁the, ▁late, ▁owner, ▁of, ▁this, ▁estate, ▁wa...   \n7  [▁but, ▁her, ▁death, ▁which, ▁happened, ▁ten, ...   \n8  [▁in, ▁the, ▁society, ▁of, ▁his, ▁ne, phe, w, ...   \n\n                                                 ess  \\\n4  [▁la, ▁familia, ▁d, ash, wood, ▁llevaba, ▁larg...   \n5  [▁su, ▁propiedad, ▁era, ▁de, ▁buen, ▁tamaño, ▁...   \n6  [▁el, ▁último, ▁dueño, ▁de, ▁esta, ▁propiedad,...   \n7  [▁pero, ▁la, ▁muerte, ▁de, ▁ella, ▁ocur, rida,...   \n8  [▁en, ▁compañía, ▁de, ▁su, ▁sob, r, ino, ▁y, ▁...   \n\n                                              en_num  \\\n4  [10, 1444, 30, 28, 744, 1121, 97, 432, 229, 23...   \n5  [260, 3647, 69, 1087, 27, 260, 5996, 69, 109, ...   \n6  [10, 1894, 4794, 30, 140, 3647, 69, 6, 2561, 2...   \n7  [136, 96, 1185, 134, 1501, 1313, 1021, 377, 90...   \n8  [43, 10, 3015, 30, 90, 161, 7033, 7948, 27, 32...   \n\n                                              es_num  \\\n4  [31, 1647, 4, 1147, 1020, 1570, 1474, 420, 653...   \n5  [48, 5069, 201, 10, 319, 4260, 24, 32, 38, 357...   \n6  [38, 1965, 3203, 10, 342, 5069, 142, 605, 46, ...   \n7  [188, 31, 1170, 10, 308, 977, 1900, 1590, 836,...   \n8  [32, 1852, 10, 48, 1930, 7937, 370, 24, 3510, ...   \n\n                                            en_paded  \\\n4  [2, 10, 1444, 30, 28, 744, 1121, 97, 432, 229,...   \n5  [2, 260, 3647, 69, 1087, 27, 260, 5996, 69, 10...   \n6  [2, 10, 1894, 4794, 30, 140, 3647, 69, 6, 2561...   \n7  [2, 136, 96, 1185, 134, 1501, 1313, 1021, 377,...   \n8  [2, 43, 10, 3015, 30, 90, 161, 7033, 7948, 27,...   \n\n                                            es_paded  \n4  [2, 31, 1647, 4, 1147, 1020, 1570, 1474, 420, ...  \n5  [2, 48, 5069, 201, 10, 319, 4260, 24, 32, 38, ...  \n6  [2, 38, 1965, 3203, 10, 342, 5069, 142, 605, 4...  \n7  [2, 188, 31, 1170, 10, 308, 977, 1900, 1590, 8...  \n8  [2, 32, 1852, 10, 48, 1930, 7937, 370, 24, 351...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>es</th>\n      <th>len1</th>\n      <th>len2</th>\n      <th>enn</th>\n      <th>ess</th>\n      <th>en_num</th>\n      <th>es_num</th>\n      <th>en_paded</th>\n      <th>es_paded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>The family of Dashwood had long been settled i...</td>\n      <td>La familia Dashwood llevaba largo tiempo afinc...</td>\n      <td>10</td>\n      <td>9</td>\n      <td>[▁the, ▁family, ▁of, ▁d, ash, wood, ▁had, ▁lon...</td>\n      <td>[▁la, ▁familia, ▁d, ash, wood, ▁llevaba, ▁larg...</td>\n      <td>[10, 1444, 30, 28, 744, 1121, 97, 432, 229, 23...</td>\n      <td>[31, 1647, 4, 1147, 1020, 1570, 1474, 420, 653...</td>\n      <td>[2, 10, 1444, 30, 28, 744, 1121, 97, 432, 229,...</td>\n      <td>[2, 31, 1647, 4, 1147, 1020, 1570, 1474, 420, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Their estate was large, and their residence wa...</td>\n      <td>Su propiedad era de buen tamaño, y en el centr...</td>\n      <td>40</td>\n      <td>41</td>\n      <td>[▁their, ▁estate, ▁was, ▁large, ▁and, ▁their, ...</td>\n      <td>[▁su, ▁propiedad, ▁era, ▁de, ▁buen, ▁tamaño, ▁...</td>\n      <td>[260, 3647, 69, 1087, 27, 260, 5996, 69, 109, ...</td>\n      <td>[48, 5069, 201, 10, 319, 4260, 24, 32, 38, 357...</td>\n      <td>[2, 260, 3647, 69, 1087, 27, 260, 5996, 69, 10...</td>\n      <td>[2, 48, 5069, 201, 10, 319, 4260, 24, 32, 38, ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The late owner of this estate was a single man...</td>\n      <td>El último dueño de esta propiedad había sido u...</td>\n      <td>34</td>\n      <td>36</td>\n      <td>[▁the, ▁late, ▁owner, ▁of, ▁this, ▁estate, ▁wa...</td>\n      <td>[▁el, ▁último, ▁dueño, ▁de, ▁esta, ▁propiedad,...</td>\n      <td>[10, 1894, 4794, 30, 140, 3647, 69, 6, 2561, 2...</td>\n      <td>[38, 1965, 3203, 10, 342, 5069, 142, 605, 46, ...</td>\n      <td>[2, 10, 1894, 4794, 30, 140, 3647, 69, 6, 2561...</td>\n      <td>[2, 38, 1965, 3203, 10, 342, 5069, 142, 605, 4...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>But her death, which happened ten years before...</td>\n      <td>Pero la muerte de ella, ocurrida diez años ant...</td>\n      <td>54</td>\n      <td>56</td>\n      <td>[▁but, ▁her, ▁death, ▁which, ▁happened, ▁ten, ...</td>\n      <td>[▁pero, ▁la, ▁muerte, ▁de, ▁ella, ▁ocur, rida,...</td>\n      <td>[136, 96, 1185, 134, 1501, 1313, 1021, 377, 90...</td>\n      <td>[188, 31, 1170, 10, 308, 977, 1900, 1590, 836,...</td>\n      <td>[2, 136, 96, 1185, 134, 1501, 1313, 1021, 377,...</td>\n      <td>[2, 188, 31, 1170, 10, 308, 977, 1900, 1590, 8...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>In the society of his nephew and niece, and th...</td>\n      <td>En compañía de su sobrino y sobrina, y de los ...</td>\n      <td>18</td>\n      <td>21</td>\n      <td>[▁in, ▁the, ▁society, ▁of, ▁his, ▁ne, phe, w, ...</td>\n      <td>[▁en, ▁compañía, ▁de, ▁su, ▁sob, r, ino, ▁y, ▁...</td>\n      <td>[43, 10, 3015, 30, 90, 161, 7033, 7948, 27, 32...</td>\n      <td>[32, 1852, 10, 48, 1930, 7937, 370, 24, 3510, ...</td>\n      <td>[2, 43, 10, 3015, 30, 90, 161, 7033, 7948, 27,...</td>\n      <td>[2, 32, 1852, 10, 48, 1930, 7937, 370, 24, 351...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"src.max().item()","metadata":{"_uuid":"c95a8b52-8653-4a1e-92eb-02ddef862439","_cell_guid":"bc6748ec-3dcc-43f6-bf94-19c575953180","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:33.069433Z","iopub.execute_input":"2025-07-09T08:26:33.069706Z","iopub.status.idle":"2025-07-09T08:26:33.124300Z","shell.execute_reply.started":"2025-07-09T08:26:33.069683Z","shell.execute_reply":"2025-07-09T08:26:33.123501Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"7999"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"BATCH_SIZE = 32\ntrain_dataset = TensorDataset(src, tgt_ip, tgt_op)\n\ntotal = len(df)\ntrain = int(0.9 * total)\nval = total-train\ntrain_dataset, val_dataset = random_split(train_dataset, [train, val])\ntrain_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\nval_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = True)","metadata":{"_uuid":"58327875-ed33-408f-b590-d85b72a01800","_cell_guid":"e92d98d0-86f1-4661-b323-ac67e4e7dad1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:33.124997Z","iopub.execute_input":"2025-07-09T08:26:33.125255Z","iopub.status.idle":"2025-07-09T08:26:33.136285Z","shell.execute_reply.started":"2025-07-09T08:26:33.125226Z","shell.execute_reply":"2025-07-09T08:26:33.135431Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"class TrainingandInference(nn.Module):\n\n    def __init__(self, en_vocab, es_vocab, max_len, lr=0.00005):\n        super(TrainingandInference, self).__init__()\n        self.en_vocab = en_vocab\n        self.es_vocab = es_vocab\n        self.ignore = ['<pad>', '<unk>', '<s>', '</s>']  # Ignore only padding, keep BPE tokens\n        self.pad_id = 0\n        self.unk_id = 1\n        self.bos_id = 2\n        self.eos_id = 3\n        \n        vocab_size_source = len(en_vocab)\n        vocab_size_target = len(es_vocab)\n        seq_length_source = max_len - 1\n        seq_length_target = max_len - 1\n        d_model = 512\n        heads = 8\n        dropout = 0.1\n        dff = 2048\n\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.model = MyTransformer(\n            vocab_size_source, vocab_size_target, \n            seq_length_source, seq_length_target,\n            self.device, d_model, heads, dropout, dff\n        ).to(self.device)\n\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n        self.criteria = nn.CrossEntropyLoss(ignore_index=0)\n        self.model.apply(self.init_weights)\n\n        self.inverse_en_vocab = {v: k for k, v in en_vocab.items()}\n        self.inverse_es_vocab = {v: k for k, v in es_vocab.items()}\n\n    def init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            nn.init.xavier_uniform_(m.weight)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.Embedding):\n            nn.init.normal_(m.weight, mean=0, std=0.02)\n\n    def train(self, train_loader, val_loader, epochs):\n        self.epochs = epochs\n        for self.epoch in range(epochs):\n            train_loss = 0\n            # train_bar = tqdm(train_loader, desc=f\"Epoch {self.epoch+1}/{epochs} [Training]\", leave=True, dynamic_ncols = True)            \n            self.model.train()\n            for i, (source, target_ip, target_op) in enumerate(train_loader):\n                source = source.to(self.device)\n                target_ip = target_ip.to(self.device)\n                target_op = target_op.to(self.device)\n\n                self.optimizer.zero_grad()\n                output = self.model(source, target_ip)\n                \n                output = output.reshape(-1, output.size(-1))\n                target_op = target_op.reshape(-1)\n\n\n                loss = self.criteria(output, target_op)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                self.optimizer.step()\n                train_loss += loss.item()\n\n                # train_bar.set_postfix(loss=f\"{train_loss / (i+1):.4f}\")\n                # train_bar.update(1)\n            self.validation(val_loader)\n            print(f\"Epoch: {self.epoch + 1}\\tTrain Loss: {train_loss / len(train_loader)}\")\n            \n    def greedy_decode(self, source, max_length = 50):\n        self.model.eval()\n        batch_size = source.size(0)\n\n        with torch.no_grad():\n            (encoder_out, src_mask) = self.model.encoder(source.to(self.device))\n    \n            decoder_input = torch.full((batch_size, 1), self.bos_id, device = self.device, dtype = torch.long)\n    \n            for step in range(max_length):\n                # look_ahead_mask = torch.triu(torch.ones((1, step + 1, step + 1), device=source.device), diagonal=1).bool()\n                # print(decoder_input.shape, encoder_out.shape)\n                \n                target_padding_mask = (decoder_input != self.pad_id).unsqueeze(1).unsqueeze(2)\n                casual_mask = self.model.decoder.casual_mask[:decoder_input.shape[1], :decoder_input.shape[1]].unsqueeze(0).unsqueeze(0)\n                tgt_mask = target_padding_mask.bool() & casual_mask.bool() \n                # print(f\"Target_padding : {target_padding_mask}\\n Casual_mask : {casual_mask}\")\n                logits = self.model.decoder(decoder_input, encoder_out, src_mask, casual_mask)\n                next_token = logits[:, -1].argmax(-1, keepdim = True)\n                decoder_input = torch.cat([decoder_input, next_token], dim = -1)\n                # print(next_token)\n                if (next_token == self.eos_id).all():\n                    break\n            return decoder_input\n    \n\n\n        \n    def validation(self, val_loader):\n        self.model.eval()\n        val_loss = 0\n        # val_bar = tqdm(val_loader, desc=f\"Epoch {self.epoch+1}/{self.epochs} [Validation]\", leave=True, dynamic_ncols = True)\n        with torch.no_grad():\n            for i, (source, target_ip, target_op) in enumerate(val_loader):\n                source = source.to(self.device)\n                target_ip = target_ip.to(self.device)\n                target_op = target_op.to(self.device)\n\n                output = self.model(source, target_ip)\n                \n                output = output.reshape(-1, output.size(-1))\n                target_op = target_op.reshape(-1)\n\n                loss = self.criteria(output, target_op)\n                val_loss += loss.item()\n                # val_bar.set_postfix(loss=f\"{val_loss / (i+1):.4f}\")\n                # val_bar.update(1)\n\n                if i < 4:\n                    predictions = self.greedy_decode(source)\n                    self.show_text(source, target_ip, predictions)\n\n            print(f\"Validation Loss: {val_loss / len(val_loader)}\")\n\n    def show_text(self, source, target_ip, target_op):\n        def decode_bpe(tokens, vocab):\n            # if tokens.dim() == 0:\n            #     tokens = tokens.unsqueeze(0)\n            text = [vocab[num.item()] for num in tokens]\n            text = \"\".join([words for words in text if words not in self.ignore])\n            text = text.replace(\"▁\", \" \")  # Convert BPE space marker to actual space\n            return text.strip()\n        # print(source.shape, target_ip.shape, target_op.shape)\n        # print([[a for a in sen ]for sen in target_op])\n        # print(target_op)\n        source_text = [decode_bpe(sen, self.inverse_en_vocab) for sen in source]\n        target_ip_text = [decode_bpe(sen, self.inverse_es_vocab) for sen in target_ip]\n        target_op_text = [decode_bpe(sen, self.inverse_es_vocab) for sen in target_op]\n\n        for i in range(1):\n            print(\"\\n\" + \"-\" * 80)\n            print(f\"ENGLISH          : {source_text[i]}\")\n            print(f\"TARGET SPANISH   : {target_ip_text[i]}\")\n            print(f\"PREDICTED SPANISH: {target_op_text[i]}\")\n            print(\"-\" * 80)","metadata":{"_uuid":"132ca2b7-87db-4cac-bc7f-b25f31c0e0f1","_cell_guid":"9feb5e8b-044e-46d0-875e-22fbf615ede2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:33.137116Z","iopub.execute_input":"2025-07-09T08:26:33.137392Z","iopub.status.idle":"2025-07-09T08:26:33.159473Z","shell.execute_reply.started":"2025-07-09T08:26:33.137370Z","shell.execute_reply":"2025-07-09T08:26:33.158591Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"print(len(es_vocab))","metadata":{"_uuid":"728af946-ccce-4611-8fea-8f778bc35426","_cell_guid":"0a660e82-4889-40ed-8e94-bd8c25781d8b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:33.160309Z","iopub.execute_input":"2025-07-09T08:26:33.160624Z","iopub.status.idle":"2025-07-09T08:26:33.176995Z","shell.execute_reply.started":"2025-07-09T08:26:33.160595Z","shell.execute_reply":"2025-07-09T08:26:33.176281Z"}},"outputs":[{"name":"stdout","text":"8000\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"TaI = TrainingandInference(en_vocab, es_vocab, max_len)\nTaI.train(train_loader,val_loader,40)","metadata":{"_uuid":"0bdd93b3-5cb2-4b9b-b8c4-ea286d4dc4b5","_cell_guid":"8ed241d7-17f3-4d26-b8f1-6dfd02db1303","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-09T08:26:33.177787Z","iopub.execute_input":"2025-07-09T08:26:33.178099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}