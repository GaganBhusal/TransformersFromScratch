{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(d_model, vocab_size)\n",
    "        # shape = [num of words * dimension of embedding layer]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(d_model)\n",
    "        # dimension same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, seq_length, dropout = 0):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(self.seq_length, self.d_model)  # To get the matrix of dimension as of embedding layer\n",
    "        positions = torch.arange(0, self.seq_length, dtype = torch.float32).unsqueeze(1)  # matrix of [seq_length x 1]\n",
    "        div_term = (positions /(torch.pow(10000, 2 * torch.arange(0, d_model, 2).float() /self.d_model))) #to calculate say (angle)  pos/(10000^(2i/dmodel))\n",
    "        pe[:, 0::2] = torch.sin(div_term)   #Apply sine formula in even positions\n",
    "        pe[:, 1::2] = torch.cos(div_term)   # Appply cosine formula in odd positions\n",
    "        \n",
    "        self.pe = pe.unsqueeze(0)  # for batches dimension [1 x seq_length x d_model]\n",
    "\n",
    "        # self.register_buffer('pe', self.pe) # By adding this in register buffer this stores pe too while saving the model without considering it as a learning parameter\n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe.required_grad(False)  #To make it not to learn\n",
    "        return self.dropout(x)\n",
    "    # def forward(self, ..):\n",
    "        # pe = torch.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, epsilon=1e-5):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = nn.Parameter(torch.ones(1))  # Scale\n",
    "        self.beta = nn.Parameter(torch.zeros(1))  # Shift\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=1, keepdim=True)\n",
    "        var = x.var(dim=1, keepdim=True) \n",
    "        return self.gamma * (x - mean) / torch.sqrt(var + self.epsilon) + self.beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dff):\n",
    "        super().__init__()\n",
    "        self.forward1 = nn.Linear(d_model, dff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.forward2 = nn.Linear(dff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.forward2(self.dropout(torch.relu(self.forward1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE I USED ALL EMBEDDING FOR EACH HEAD AND CONCATENATE THEM AND USE LINEAR TRANSFORMATION TO GET THE OUTPUT SAME DIMENSION AS INPUT\n",
    "# class MultiHeadAttention(nn.Module):\n",
    "\n",
    "#     def __init__(self, d_model, heads, dropout = 0.5):\n",
    "#         super(MultiHeadAttention, self).__init__()\n",
    "#         self.d_model = d_model\n",
    "#         self.heads = heads\n",
    "#         self.dropout = dropout\n",
    "\n",
    "#         self.w_q = nn.ModuleList(nn.Linear(d_model, d_model) for _ in range(heads))\n",
    "#         self.w_k = nn.ModuleList(nn.Linear(d_model, d_model) for _ in range(heads))\n",
    "#         self.w_v = nn.ModuleList(nn.Linear(d_model, d_model) for _ in range(heads))\n",
    "\n",
    "#         self.w_o = nn.Linear(d_model * heads, d_model)\n",
    "\n",
    "#         self.softmax = nn.Softmax(dim = -1)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "#     def forward(self, embeded_layer):\n",
    "\n",
    "#         attention_outputs = []\n",
    "\n",
    "#         for head in range(self.heads):\n",
    "        \n",
    "#             query = self.w_q[head](embeded_layer)\n",
    "#             key = self.w_k[head](embeded_layer)\n",
    "#             value = self.w_v[head](embeded_layer)\n",
    "\n",
    "#             similarity = torch.matmul(query, torch.transpose(key, -2, -1))  / math.sqrt(self.d_model)\n",
    "\n",
    "#             sim = self.softmax(similarity)\n",
    "#             sim = self.dropout(sim)\n",
    "\n",
    "#             final = torch.matmul(sim, value)\n",
    "\n",
    "#             attention_outputs.append(final)\n",
    "            \n",
    "#         concat_matrix = torch.cat(attention_outputs, -1)\n",
    "#         print(concat_matrix.shape)\n",
    "#         print(self.w_o.weight.shape)\n",
    "#         return self.w_o(concat_matrix)\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, heads, dropout = 0.5):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = heads\n",
    "        self.d_heads = d_model//heads\n",
    "\n",
    "        self.w_q = nn.Linear(d_model, d_model, bias = False)\n",
    "        self.w_v = nn.Linear(d_model, d_model, bias = False)\n",
    "        self.w_k = nn.Linear(d_model, d_model, bias = False)\n",
    "\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    \n",
    "    # def splitweights(self, x):\n",
    "    #     batch_size, seq_len, d_model = x.shape\n",
    "    #     x = x.view(batch_size, seq_len, self.heads, -1)\n",
    "    #     return x.permute(0, 2, 1, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        print(x.shape)\n",
    "        print(self.w_q.weight.shape)\n",
    "\n",
    "        query = self.w_q(x).view(batch_size, seq_len, self.heads, -1).permute(0, 2, 1, 3)\n",
    "        key = self.w_k(x).view(batch_size, seq_len, self.heads, -1).permute(0, 2, 1, 3)\n",
    "        value = self.w_v(x).view(batch_size, seq_len, self.heads, -1).permute(0, 2, 1, 3)\n",
    "\n",
    "        # query = self.splitweights(self.w_q(x))\n",
    "        # key = self.splitweights(self.w_k(x))\n",
    "        # value = self.splitweights(self.w_v(x))\n",
    "        # print(query.shape)\n",
    "\n",
    "        similarity = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_heads)\n",
    "\n",
    "        # print(similarity.shape)\n",
    "\n",
    "        if mask is not None:\n",
    "            # print(mask)\n",
    "            mask = mask.unsqueeze(0).unsqueeze(0)\n",
    "            print(mask)\n",
    "            # print(similarity)\n",
    "            similarity = similarity.masked_fill(mask == 0, float('-inf'))\n",
    "        print(similarity)\n",
    "\n",
    "        sim = self.softmax(similarity)\n",
    "        print(sim)\n",
    "        sim = self.dropout(sim)\n",
    "\n",
    "        # print(sim)\n",
    "\n",
    "        final = torch.matmul(sim, value)\n",
    "\n",
    "        final = final.permute(0, 2, 1, 3).contiguous()\n",
    "        final = final.view(batch_size, seq_len, self.d_model)\n",
    "        \n",
    "\n",
    "        # print(final.shape)\n",
    "        return self.w_o(final)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 15])\n",
      "torch.Size([15, 15])\n",
      "tensor([[[[1., 0., 0., 0.],\n",
      "          [1., 1., 0., 0.],\n",
      "          [1., 1., 1., 0.],\n",
      "          [1., 1., 1., 1.]]]])\n",
      "tensor([[[[ 0.0530,    -inf,    -inf,    -inf],\n",
      "          [ 0.0033,  0.0166,    -inf,    -inf],\n",
      "          [ 0.0483,  0.1619,  0.0580,    -inf],\n",
      "          [ 0.0183,  0.0183, -0.0060, -0.0061]],\n",
      "\n",
      "         [[ 0.1545,    -inf,    -inf,    -inf],\n",
      "          [-0.0061, -0.0228,    -inf,    -inf],\n",
      "          [ 0.0425, -0.0642, -0.0058,    -inf],\n",
      "          [ 0.0111, -0.0543, -0.0131,  0.0149]],\n",
      "\n",
      "         [[ 0.0356,    -inf,    -inf,    -inf],\n",
      "          [-0.0762, -0.0924,    -inf,    -inf],\n",
      "          [-0.1328, -0.0885, -0.2134,    -inf],\n",
      "          [ 0.0040, -0.0672,  0.0123, -0.0212]]],\n",
      "\n",
      "\n",
      "        [[[-0.0996,    -inf,    -inf,    -inf],\n",
      "          [-0.0412,  0.0545,    -inf,    -inf],\n",
      "          [-0.0444,  0.0434,  0.0496,    -inf],\n",
      "          [-0.0469,  0.0691,  0.1064,  0.0651]],\n",
      "\n",
      "         [[-0.0185,    -inf,    -inf,    -inf],\n",
      "          [-0.0340, -0.0399,    -inf,    -inf],\n",
      "          [ 0.0311, -0.0071, -0.0111,    -inf],\n",
      "          [-0.1105, -0.0457, -0.0729, -0.0211]],\n",
      "\n",
      "         [[-0.1133,    -inf,    -inf,    -inf],\n",
      "          [-0.1803, -0.1216,    -inf,    -inf],\n",
      "          [ 0.0140,  0.0296,  0.0692,    -inf],\n",
      "          [-0.1304, -0.0621, -0.0844, -0.0368]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4967, 0.5033, 0.0000, 0.0000],\n",
      "          [0.3195, 0.3579, 0.3226, 0.0000],\n",
      "          [0.2530, 0.2530, 0.2470, 0.2470]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5042, 0.4958, 0.0000, 0.0000],\n",
      "          [0.3507, 0.3152, 0.3341, 0.0000],\n",
      "          [0.2553, 0.2392, 0.2492, 0.2563]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5040, 0.4960, 0.0000, 0.0000],\n",
      "          [0.3370, 0.3522, 0.3108, 0.0000],\n",
      "          [0.2555, 0.2379, 0.2576, 0.2491]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4761, 0.5239, 0.0000, 0.0000],\n",
      "          [0.3135, 0.3422, 0.3443, 0.0000],\n",
      "          [0.2269, 0.2548, 0.2645, 0.2538]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5015, 0.4985, 0.0000, 0.0000],\n",
      "          [0.3423, 0.3295, 0.3282, 0.0000],\n",
      "          [0.2382, 0.2541, 0.2473, 0.2604]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4853, 0.5147, 0.0000, 0.0000],\n",
      "          [0.3255, 0.3306, 0.3439, 0.0000],\n",
      "          [0.2372, 0.2540, 0.2484, 0.2605]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2267,  0.3774, -0.2637, -0.2610,  0.2711,  0.2970,  0.0651,\n",
       "          -0.1511,  0.1428,  0.3497,  0.0067, -0.0603,  0.1559,  0.1714,\n",
       "          -0.0256],\n",
       "         [-0.0285,  0.1654, -0.3539, -0.2735,  0.3567,  0.2231,  0.2674,\n",
       "          -0.3353,  0.0355,  0.2328, -0.0428, -0.0401,  0.2225, -0.0186,\n",
       "           0.0456],\n",
       "         [-0.5492,  0.3152, -0.3860, -0.1506,  0.1803,  0.1413,  0.3592,\n",
       "          -0.2442, -0.0326,  0.1047,  0.0372, -0.1802, -0.2015, -0.0544,\n",
       "          -0.2417],\n",
       "         [-0.2823,  0.4167, -0.3120, -0.2251,  0.1815,  0.1941,  0.2161,\n",
       "          -0.2376, -0.0423,  0.2677, -0.0089, -0.0548,  0.0963, -0.1178,\n",
       "          -0.0113]],\n",
       "\n",
       "        [[-0.2422,  0.1733, -0.1432, -0.4252,  0.3160,  0.3669,  0.1549,\n",
       "          -0.2144,  0.1294, -0.0208, -0.0585, -0.1196, -0.0286,  0.0484,\n",
       "          -0.0227],\n",
       "         [-0.2519,  0.3443, -0.5431, -0.4081,  0.1177,  0.4339,  0.2558,\n",
       "          -0.2460,  0.1468,  0.2038,  0.0711, -0.1348,  0.1013, -0.0627,\n",
       "          -0.1987],\n",
       "         [-0.1528,  0.2626, -0.4187, -0.4821,  0.3218,  0.3801,  0.3560,\n",
       "          -0.2146,  0.0150,  0.1441,  0.0799, -0.1979,  0.0784, -0.2472,\n",
       "          -0.1804],\n",
       "         [-0.5079,  0.2052, -0.4453, -0.2065,  0.2147,  0.2353,  0.3122,\n",
       "          -0.2462,  0.0408,  0.0412,  0.0231, -0.2605, -0.1313, -0.1295,\n",
       "          -0.2382]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.tril(torch.ones(4, 4))\n",
    "x = torch.rand(2, 4 ,15)\n",
    "a = MultiHeadAttention(15, 3)\n",
    "a(x, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model ,dropout):\n",
    "\n",
    "        super(ResidualConnection, self).__init__()\n",
    "        self.ln = LayerNormalization()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        return self.ln(x1 + self.dropout(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, attention, rc, ff):\n",
    "\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.attention = attention\n",
    "        self.rc = rc\n",
    "        self.ff = ff\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x1 = self.attention(x)\n",
    "        x2 = self.rc(x, x1)\n",
    "\n",
    "        x3 = self.ff(x2)\n",
    "        x4 = self.rc(x2, x3)\n",
    "        return x4\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding, pos_encoding, attention, rc, ff, n= 6):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = embedding\n",
    "        self.pos_encoding = pos_encoding\n",
    "        \n",
    "        self.encoder_blocks = nn.ModuleList(EncoderBlock(attention, rc, ff) for _ in range(n))\n",
    "        print(type(self.encoder_blocks))\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.pos_encoding(self.embedding(x))\n",
    "\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.container.ModuleList'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder_blocks): ModuleList(\n",
       "    (0-5): 6 x EncoderBlock()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder(0, 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = torch.rand((4, 3, 3))\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = nn.Softmax(dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8063, 0.8474, 0.3038, 0.2912],\n",
       "        [0.7710, 0.5077, 0.0820, 0.4452],\n",
       "        [0.9906, 0.8621, 0.5196, 0.7618],\n",
       "        [0.9640, 0.7600, 0.2415, 0.9532],\n",
       "        [0.7602, 0.2326, 0.6311, 0.9994]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(4, 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4523, 0.7673, 0.4615, 0.7689, 0.4221, 0.0651],\n",
       "         [0.0223, 0.9863, 0.1898, 0.7654, 0.9906, 0.9972],\n",
       "         [0.2631, 0.7573, 0.2952, 0.9816, 0.9212, 0.7088],\n",
       "         [0.0012, 0.7520, 0.7898, 0.9398, 0.4272, 0.2188],\n",
       "         [0.2945, 0.0889, 0.1906, 0.3348, 0.8903, 0.8236]],\n",
       "\n",
       "        [[0.6094, 0.0213, 0.1959, 0.9292, 0.7505, 0.4193],\n",
       "         [0.3287, 0.3430, 0.8965, 0.3555, 0.3171, 0.1416],\n",
       "         [0.6776, 0.4158, 0.4936, 0.3396, 0.0263, 0.8206],\n",
       "         [0.6837, 0.3355, 0.0200, 0.8911, 0.7474, 0.6377],\n",
       "         [0.5047, 0.9601, 0.4932, 0.4784, 0.2009, 0.4425]],\n",
       "\n",
       "        [[0.1479, 0.2026, 0.9293, 0.8562, 0.6848, 0.2807],\n",
       "         [0.1583, 0.9729, 0.0499, 0.6895, 0.3252, 0.5378],\n",
       "         [0.3896, 0.3278, 0.4169, 0.1010, 0.4727, 0.4761],\n",
       "         [0.2407, 0.8861, 0.8218, 0.4522, 0.6229, 0.4474],\n",
       "         [0.5529, 0.6962, 0.3056, 0.0646, 0.2397, 0.5979]],\n",
       "\n",
       "        [[0.3858, 0.7512, 0.5848, 0.4403, 0.4271, 0.7991],\n",
       "         [0.9456, 0.8152, 0.4946, 0.4556, 0.3767, 0.1086],\n",
       "         [0.3785, 0.8840, 0.7174, 0.2326, 0.4215, 0.3070],\n",
       "         [0.3020, 0.0776, 0.9420, 0.8555, 0.5795, 0.9104],\n",
       "         [0.4973, 0.9832, 0.6352, 0.9379, 0.9139, 0.6952]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.view(4, 5, 2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4523, 0.7673, 0.4615],\n",
       "          [0.0223, 0.9863, 0.1898],\n",
       "          [0.2631, 0.7573, 0.2952],\n",
       "          [0.0012, 0.7520, 0.7898],\n",
       "          [0.2945, 0.0889, 0.1906]],\n",
       "\n",
       "         [[0.7689, 0.4221, 0.0651],\n",
       "          [0.7654, 0.9906, 0.9972],\n",
       "          [0.9816, 0.9212, 0.7088],\n",
       "          [0.9398, 0.4272, 0.2188],\n",
       "          [0.3348, 0.8903, 0.8236]]],\n",
       "\n",
       "\n",
       "        [[[0.6094, 0.0213, 0.1959],\n",
       "          [0.3287, 0.3430, 0.8965],\n",
       "          [0.6776, 0.4158, 0.4936],\n",
       "          [0.6837, 0.3355, 0.0200],\n",
       "          [0.5047, 0.9601, 0.4932]],\n",
       "\n",
       "         [[0.9292, 0.7505, 0.4193],\n",
       "          [0.3555, 0.3171, 0.1416],\n",
       "          [0.3396, 0.0263, 0.8206],\n",
       "          [0.8911, 0.7474, 0.6377],\n",
       "          [0.4784, 0.2009, 0.4425]]],\n",
       "\n",
       "\n",
       "        [[[0.1479, 0.2026, 0.9293],\n",
       "          [0.1583, 0.9729, 0.0499],\n",
       "          [0.3896, 0.3278, 0.4169],\n",
       "          [0.2407, 0.8861, 0.8218],\n",
       "          [0.5529, 0.6962, 0.3056]],\n",
       "\n",
       "         [[0.8562, 0.6848, 0.2807],\n",
       "          [0.6895, 0.3252, 0.5378],\n",
       "          [0.1010, 0.4727, 0.4761],\n",
       "          [0.4522, 0.6229, 0.4474],\n",
       "          [0.0646, 0.2397, 0.5979]]],\n",
       "\n",
       "\n",
       "        [[[0.3858, 0.7512, 0.5848],\n",
       "          [0.9456, 0.8152, 0.4946],\n",
       "          [0.3785, 0.8840, 0.7174],\n",
       "          [0.3020, 0.0776, 0.9420],\n",
       "          [0.4973, 0.9832, 0.6352]],\n",
       "\n",
       "         [[0.4403, 0.4271, 0.7991],\n",
       "          [0.4556, 0.3767, 0.1086],\n",
       "          [0.2326, 0.4215, 0.3070],\n",
       "          [0.8555, 0.5795, 0.9104],\n",
       "          [0.9379, 0.9139, 0.6952]]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
